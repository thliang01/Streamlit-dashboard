{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QUICKSTART-Pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORpDosJOJddskpx5OLUxsk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thliang01/Streamlit-dashboard/blob/master/QUICKSTART_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kfish2d-oojb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "ixIla1h5pF-7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1e2uryspMAR",
        "outputId": "7080e11e-e364-485a-c9f3-29c94bf29c94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZrXETW_pPuC",
        "outputId": "9938394c-d08b-47ab-d728-7cbcf163b7ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "jZUsM8aipZcC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "oHaXIKropdz1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "v1BLjwxZphL2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1aCvamlpifm",
        "outputId": "a31ce044-42e0-450c-f762-e2a00a668e9d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.553508  [    0/60000]\n",
            "loss: 0.656120  [ 6400/60000]\n",
            "loss: 0.434658  [12800/60000]\n",
            "loss: 0.692166  [19200/60000]\n",
            "loss: 0.610702  [25600/60000]\n",
            "loss: 0.591948  [32000/60000]\n",
            "loss: 0.631596  [38400/60000]\n",
            "loss: 0.678228  [44800/60000]\n",
            "loss: 0.658523  [51200/60000]\n",
            "loss: 0.608478  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 78.8%, Avg loss: 0.605460 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.540763  [    0/60000]\n",
            "loss: 0.644049  [ 6400/60000]\n",
            "loss: 0.425270  [12800/60000]\n",
            "loss: 0.682884  [19200/60000]\n",
            "loss: 0.603822  [25600/60000]\n",
            "loss: 0.585562  [32000/60000]\n",
            "loss: 0.619764  [38400/60000]\n",
            "loss: 0.673866  [44800/60000]\n",
            "loss: 0.653508  [51200/60000]\n",
            "loss: 0.598495  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.1%, Avg loss: 0.596672 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.528961  [    0/60000]\n",
            "loss: 0.632939  [ 6400/60000]\n",
            "loss: 0.416654  [12800/60000]\n",
            "loss: 0.674087  [19200/60000]\n",
            "loss: 0.597281  [25600/60000]\n",
            "loss: 0.579656  [32000/60000]\n",
            "loss: 0.608754  [38400/60000]\n",
            "loss: 0.670279  [44800/60000]\n",
            "loss: 0.649285  [51200/60000]\n",
            "loss: 0.588882  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.4%, Avg loss: 0.588552 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.517975  [    0/60000]\n",
            "loss: 0.622665  [ 6400/60000]\n",
            "loss: 0.408685  [12800/60000]\n",
            "loss: 0.665696  [19200/60000]\n",
            "loss: 0.590964  [25600/60000]\n",
            "loss: 0.574075  [32000/60000]\n",
            "loss: 0.598502  [38400/60000]\n",
            "loss: 0.667423  [44800/60000]\n",
            "loss: 0.645679  [51200/60000]\n",
            "loss: 0.579641  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.6%, Avg loss: 0.581036 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.507738  [    0/60000]\n",
            "loss: 0.613114  [ 6400/60000]\n",
            "loss: 0.401272  [12800/60000]\n",
            "loss: 0.657722  [19200/60000]\n",
            "loss: 0.584782  [25600/60000]\n",
            "loss: 0.568819  [32000/60000]\n",
            "loss: 0.588966  [38400/60000]\n",
            "loss: 0.665247  [44800/60000]\n",
            "loss: 0.642678  [51200/60000]\n",
            "loss: 0.570765  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.9%, Avg loss: 0.574064 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.498060  [    0/60000]\n",
            "loss: 0.604240  [ 6400/60000]\n",
            "loss: 0.394401  [12800/60000]\n",
            "loss: 0.650124  [19200/60000]\n",
            "loss: 0.578703  [25600/60000]\n",
            "loss: 0.563791  [32000/60000]\n",
            "loss: 0.580055  [38400/60000]\n",
            "loss: 0.663558  [44800/60000]\n",
            "loss: 0.640087  [51200/60000]\n",
            "loss: 0.562248  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg loss: 0.567586 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.488927  [    0/60000]\n",
            "loss: 0.596058  [ 6400/60000]\n",
            "loss: 0.387992  [12800/60000]\n",
            "loss: 0.642812  [19200/60000]\n",
            "loss: 0.572741  [25600/60000]\n",
            "loss: 0.558957  [32000/60000]\n",
            "loss: 0.571738  [38400/60000]\n",
            "loss: 0.662356  [44800/60000]\n",
            "loss: 0.637895  [51200/60000]\n",
            "loss: 0.554022  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.3%, Avg loss: 0.561565 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.480236  [    0/60000]\n",
            "loss: 0.588451  [ 6400/60000]\n",
            "loss: 0.381978  [12800/60000]\n",
            "loss: 0.635830  [19200/60000]\n",
            "loss: 0.566804  [25600/60000]\n",
            "loss: 0.554240  [32000/60000]\n",
            "loss: 0.563998  [38400/60000]\n",
            "loss: 0.661544  [44800/60000]\n",
            "loss: 0.635974  [51200/60000]\n",
            "loss: 0.546040  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.6%, Avg loss: 0.555947 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.471988  [    0/60000]\n",
            "loss: 0.581298  [ 6400/60000]\n",
            "loss: 0.376357  [12800/60000]\n",
            "loss: 0.629135  [19200/60000]\n",
            "loss: 0.560962  [25600/60000]\n",
            "loss: 0.549645  [32000/60000]\n",
            "loss: 0.556692  [38400/60000]\n",
            "loss: 0.661050  [44800/60000]\n",
            "loss: 0.634256  [51200/60000]\n",
            "loss: 0.538248  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.7%, Avg loss: 0.550692 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.464126  [    0/60000]\n",
            "loss: 0.574619  [ 6400/60000]\n",
            "loss: 0.371092  [12800/60000]\n",
            "loss: 0.622746  [19200/60000]\n",
            "loss: 0.555234  [25600/60000]\n",
            "loss: 0.545037  [32000/60000]\n",
            "loss: 0.549893  [38400/60000]\n",
            "loss: 0.660860  [44800/60000]\n",
            "loss: 0.632647  [51200/60000]\n",
            "loss: 0.530721  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.9%, Avg loss: 0.545784 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.456582  [    0/60000]\n",
            "loss: 0.568409  [ 6400/60000]\n",
            "loss: 0.366147  [12800/60000]\n",
            "loss: 0.616595  [19200/60000]\n",
            "loss: 0.549550  [25600/60000]\n",
            "loss: 0.540521  [32000/60000]\n",
            "loss: 0.543613  [38400/60000]\n",
            "loss: 0.660899  [44800/60000]\n",
            "loss: 0.631183  [51200/60000]\n",
            "loss: 0.523471  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.0%, Avg loss: 0.541189 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.449411  [    0/60000]\n",
            "loss: 0.562600  [ 6400/60000]\n",
            "loss: 0.361481  [12800/60000]\n",
            "loss: 0.610691  [19200/60000]\n",
            "loss: 0.544014  [25600/60000]\n",
            "loss: 0.536159  [32000/60000]\n",
            "loss: 0.537714  [38400/60000]\n",
            "loss: 0.661095  [44800/60000]\n",
            "loss: 0.629774  [51200/60000]\n",
            "loss: 0.516534  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.0%, Avg loss: 0.536880 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.442563  [    0/60000]\n",
            "loss: 0.557220  [ 6400/60000]\n",
            "loss: 0.357033  [12800/60000]\n",
            "loss: 0.604980  [19200/60000]\n",
            "loss: 0.538528  [25600/60000]\n",
            "loss: 0.531873  [32000/60000]\n",
            "loss: 0.532224  [38400/60000]\n",
            "loss: 0.661396  [44800/60000]\n",
            "loss: 0.628375  [51200/60000]\n",
            "loss: 0.509843  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.2%, Avg loss: 0.532830 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.435984  [    0/60000]\n",
            "loss: 0.552187  [ 6400/60000]\n",
            "loss: 0.352817  [12800/60000]\n",
            "loss: 0.599450  [19200/60000]\n",
            "loss: 0.533192  [25600/60000]\n",
            "loss: 0.527634  [32000/60000]\n",
            "loss: 0.527074  [38400/60000]\n",
            "loss: 0.661692  [44800/60000]\n",
            "loss: 0.626958  [51200/60000]\n",
            "loss: 0.503459  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.3%, Avg loss: 0.529015 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.429679  [    0/60000]\n",
            "loss: 0.547462  [ 6400/60000]\n",
            "loss: 0.348846  [12800/60000]\n",
            "loss: 0.594193  [19200/60000]\n",
            "loss: 0.527983  [25600/60000]\n",
            "loss: 0.523455  [32000/60000]\n",
            "loss: 0.522215  [38400/60000]\n",
            "loss: 0.661979  [44800/60000]\n",
            "loss: 0.625567  [51200/60000]\n",
            "loss: 0.497296  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 0.525416 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.423638  [    0/60000]\n",
            "loss: 0.543038  [ 6400/60000]\n",
            "loss: 0.345083  [12800/60000]\n",
            "loss: 0.589128  [19200/60000]\n",
            "loss: 0.522866  [25600/60000]\n",
            "loss: 0.519373  [32000/60000]\n",
            "loss: 0.517675  [38400/60000]\n",
            "loss: 0.662243  [44800/60000]\n",
            "loss: 0.624134  [51200/60000]\n",
            "loss: 0.491440  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.522015 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.417787  [    0/60000]\n",
            "loss: 0.538860  [ 6400/60000]\n",
            "loss: 0.341499  [12800/60000]\n",
            "loss: 0.584248  [19200/60000]\n",
            "loss: 0.517884  [25600/60000]\n",
            "loss: 0.515420  [32000/60000]\n",
            "loss: 0.513419  [38400/60000]\n",
            "loss: 0.662423  [44800/60000]\n",
            "loss: 0.622603  [51200/60000]\n",
            "loss: 0.485888  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.6%, Avg loss: 0.518796 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.412170  [    0/60000]\n",
            "loss: 0.534945  [ 6400/60000]\n",
            "loss: 0.338089  [12800/60000]\n",
            "loss: 0.579547  [19200/60000]\n",
            "loss: 0.513058  [25600/60000]\n",
            "loss: 0.511573  [32000/60000]\n",
            "loss: 0.509404  [38400/60000]\n",
            "loss: 0.662584  [44800/60000]\n",
            "loss: 0.621058  [51200/60000]\n",
            "loss: 0.480602  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.7%, Avg loss: 0.515740 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.406738  [    0/60000]\n",
            "loss: 0.531308  [ 6400/60000]\n",
            "loss: 0.334837  [12800/60000]\n",
            "loss: 0.575029  [19200/60000]\n",
            "loss: 0.508373  [25600/60000]\n",
            "loss: 0.507784  [32000/60000]\n",
            "loss: 0.505651  [38400/60000]\n",
            "loss: 0.662653  [44800/60000]\n",
            "loss: 0.619403  [51200/60000]\n",
            "loss: 0.475576  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 0.512843 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.401476  [    0/60000]\n",
            "loss: 0.527898  [ 6400/60000]\n",
            "loss: 0.331735  [12800/60000]\n",
            "loss: 0.570658  [19200/60000]\n",
            "loss: 0.503767  [25600/60000]\n",
            "loss: 0.504101  [32000/60000]\n",
            "loss: 0.502093  [38400/60000]\n",
            "loss: 0.662575  [44800/60000]\n",
            "loss: 0.617712  [51200/60000]\n",
            "loss: 0.470813  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.9%, Avg loss: 0.510091 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.396362  [    0/60000]\n",
            "loss: 0.524676  [ 6400/60000]\n",
            "loss: 0.328774  [12800/60000]\n",
            "loss: 0.566441  [19200/60000]\n",
            "loss: 0.499289  [25600/60000]\n",
            "loss: 0.500478  [32000/60000]\n",
            "loss: 0.498729  [38400/60000]\n",
            "loss: 0.662371  [44800/60000]\n",
            "loss: 0.616018  [51200/60000]\n",
            "loss: 0.466258  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.1%, Avg loss: 0.507472 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.391446  [    0/60000]\n",
            "loss: 0.521607  [ 6400/60000]\n",
            "loss: 0.325967  [12800/60000]\n",
            "loss: 0.562378  [19200/60000]\n",
            "loss: 0.494998  [25600/60000]\n",
            "loss: 0.497015  [32000/60000]\n",
            "loss: 0.495549  [38400/60000]\n",
            "loss: 0.662015  [44800/60000]\n",
            "loss: 0.614296  [51200/60000]\n",
            "loss: 0.461957  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.1%, Avg loss: 0.504972 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.386681  [    0/60000]\n",
            "loss: 0.518701  [ 6400/60000]\n",
            "loss: 0.323259  [12800/60000]\n",
            "loss: 0.558422  [19200/60000]\n",
            "loss: 0.490769  [25600/60000]\n",
            "loss: 0.493654  [32000/60000]\n",
            "loss: 0.492486  [38400/60000]\n",
            "loss: 0.661542  [44800/60000]\n",
            "loss: 0.612561  [51200/60000]\n",
            "loss: 0.457918  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 0.502591 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.382052  [    0/60000]\n",
            "loss: 0.515952  [ 6400/60000]\n",
            "loss: 0.320629  [12800/60000]\n",
            "loss: 0.554627  [19200/60000]\n",
            "loss: 0.486740  [25600/60000]\n",
            "loss: 0.490371  [32000/60000]\n",
            "loss: 0.489587  [38400/60000]\n",
            "loss: 0.660957  [44800/60000]\n",
            "loss: 0.610826  [51200/60000]\n",
            "loss: 0.454081  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 0.500309 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.377584  [    0/60000]\n",
            "loss: 0.513355  [ 6400/60000]\n",
            "loss: 0.318105  [12800/60000]\n",
            "loss: 0.550978  [19200/60000]\n",
            "loss: 0.482826  [25600/60000]\n",
            "loss: 0.487160  [32000/60000]\n",
            "loss: 0.486818  [38400/60000]\n",
            "loss: 0.660285  [44800/60000]\n",
            "loss: 0.609075  [51200/60000]\n",
            "loss: 0.450454  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 0.498125 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.373209  [    0/60000]\n",
            "loss: 0.510911  [ 6400/60000]\n",
            "loss: 0.315670  [12800/60000]\n",
            "loss: 0.547462  [19200/60000]\n",
            "loss: 0.479004  [25600/60000]\n",
            "loss: 0.484061  [32000/60000]\n",
            "loss: 0.484142  [38400/60000]\n",
            "loss: 0.659459  [44800/60000]\n",
            "loss: 0.607255  [51200/60000]\n",
            "loss: 0.447066  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.3%, Avg loss: 0.496037 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.368964  [    0/60000]\n",
            "loss: 0.508612  [ 6400/60000]\n",
            "loss: 0.313310  [12800/60000]\n",
            "loss: 0.544072  [19200/60000]\n",
            "loss: 0.475326  [25600/60000]\n",
            "loss: 0.481080  [32000/60000]\n",
            "loss: 0.481604  [38400/60000]\n",
            "loss: 0.658545  [44800/60000]\n",
            "loss: 0.605432  [51200/60000]\n",
            "loss: 0.443862  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.4%, Avg loss: 0.494031 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.364887  [    0/60000]\n",
            "loss: 0.506402  [ 6400/60000]\n",
            "loss: 0.311030  [12800/60000]\n",
            "loss: 0.540849  [19200/60000]\n",
            "loss: 0.471787  [25600/60000]\n",
            "loss: 0.478209  [32000/60000]\n",
            "loss: 0.479186  [38400/60000]\n",
            "loss: 0.657505  [44800/60000]\n",
            "loss: 0.603628  [51200/60000]\n",
            "loss: 0.440853  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.5%, Avg loss: 0.492104 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.360917  [    0/60000]\n",
            "loss: 0.504286  [ 6400/60000]\n",
            "loss: 0.308824  [12800/60000]\n",
            "loss: 0.537778  [19200/60000]\n",
            "loss: 0.468370  [25600/60000]\n",
            "loss: 0.475413  [32000/60000]\n",
            "loss: 0.476830  [38400/60000]\n",
            "loss: 0.656396  [44800/60000]\n",
            "loss: 0.601818  [51200/60000]\n",
            "loss: 0.438025  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.7%, Avg loss: 0.490252 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.357067  [    0/60000]\n",
            "loss: 0.502233  [ 6400/60000]\n",
            "loss: 0.306665  [12800/60000]\n",
            "loss: 0.534840  [19200/60000]\n",
            "loss: 0.465106  [25600/60000]\n",
            "loss: 0.472671  [32000/60000]\n",
            "loss: 0.474534  [38400/60000]\n",
            "loss: 0.655164  [44800/60000]\n",
            "loss: 0.599966  [51200/60000]\n",
            "loss: 0.435402  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.7%, Avg loss: 0.488468 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.353330  [    0/60000]\n",
            "loss: 0.500254  [ 6400/60000]\n",
            "loss: 0.304609  [12800/60000]\n",
            "loss: 0.532021  [19200/60000]\n",
            "loss: 0.461950  [25600/60000]\n",
            "loss: 0.470080  [32000/60000]\n",
            "loss: 0.472339  [38400/60000]\n",
            "loss: 0.653893  [44800/60000]\n",
            "loss: 0.598136  [51200/60000]\n",
            "loss: 0.432906  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.8%, Avg loss: 0.486748 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.349689  [    0/60000]\n",
            "loss: 0.498336  [ 6400/60000]\n",
            "loss: 0.302623  [12800/60000]\n",
            "loss: 0.529357  [19200/60000]\n",
            "loss: 0.458832  [25600/60000]\n",
            "loss: 0.467625  [32000/60000]\n",
            "loss: 0.470191  [38400/60000]\n",
            "loss: 0.652610  [44800/60000]\n",
            "loss: 0.596326  [51200/60000]\n",
            "loss: 0.430521  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.485089 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.346181  [    0/60000]\n",
            "loss: 0.496457  [ 6400/60000]\n",
            "loss: 0.300680  [12800/60000]\n",
            "loss: 0.526765  [19200/60000]\n",
            "loss: 0.455844  [25600/60000]\n",
            "loss: 0.465318  [32000/60000]\n",
            "loss: 0.468119  [38400/60000]\n",
            "loss: 0.651258  [44800/60000]\n",
            "loss: 0.594605  [51200/60000]\n",
            "loss: 0.428228  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.483487 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.342806  [    0/60000]\n",
            "loss: 0.494640  [ 6400/60000]\n",
            "loss: 0.298820  [12800/60000]\n",
            "loss: 0.524279  [19200/60000]\n",
            "loss: 0.452933  [25600/60000]\n",
            "loss: 0.463090  [32000/60000]\n",
            "loss: 0.466107  [38400/60000]\n",
            "loss: 0.649820  [44800/60000]\n",
            "loss: 0.592902  [51200/60000]\n",
            "loss: 0.426104  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.481937 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.339540  [    0/60000]\n",
            "loss: 0.492882  [ 6400/60000]\n",
            "loss: 0.297001  [12800/60000]\n",
            "loss: 0.521903  [19200/60000]\n",
            "loss: 0.450127  [25600/60000]\n",
            "loss: 0.461003  [32000/60000]\n",
            "loss: 0.464151  [38400/60000]\n",
            "loss: 0.648391  [44800/60000]\n",
            "loss: 0.591201  [51200/60000]\n",
            "loss: 0.424084  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.0%, Avg loss: 0.480436 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.336341  [    0/60000]\n",
            "loss: 0.491168  [ 6400/60000]\n",
            "loss: 0.295246  [12800/60000]\n",
            "loss: 0.519609  [19200/60000]\n",
            "loss: 0.447434  [25600/60000]\n",
            "loss: 0.458982  [32000/60000]\n",
            "loss: 0.462243  [38400/60000]\n",
            "loss: 0.646901  [44800/60000]\n",
            "loss: 0.589550  [51200/60000]\n",
            "loss: 0.422124  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.1%, Avg loss: 0.478980 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.333235  [    0/60000]\n",
            "loss: 0.489480  [ 6400/60000]\n",
            "loss: 0.293529  [12800/60000]\n",
            "loss: 0.517433  [19200/60000]\n",
            "loss: 0.444786  [25600/60000]\n",
            "loss: 0.457026  [32000/60000]\n",
            "loss: 0.460447  [38400/60000]\n",
            "loss: 0.645400  [44800/60000]\n",
            "loss: 0.587906  [51200/60000]\n",
            "loss: 0.420249  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 0.477565 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.330264  [    0/60000]\n",
            "loss: 0.487834  [ 6400/60000]\n",
            "loss: 0.291870  [12800/60000]\n",
            "loss: 0.515356  [19200/60000]\n",
            "loss: 0.442204  [25600/60000]\n",
            "loss: 0.455114  [32000/60000]\n",
            "loss: 0.458741  [38400/60000]\n",
            "loss: 0.643844  [44800/60000]\n",
            "loss: 0.586285  [51200/60000]\n",
            "loss: 0.418470  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 0.476190 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.327406  [    0/60000]\n",
            "loss: 0.486251  [ 6400/60000]\n",
            "loss: 0.290274  [12800/60000]\n",
            "loss: 0.513320  [19200/60000]\n",
            "loss: 0.439689  [25600/60000]\n",
            "loss: 0.453284  [32000/60000]\n",
            "loss: 0.457092  [38400/60000]\n",
            "loss: 0.642275  [44800/60000]\n",
            "loss: 0.584706  [51200/60000]\n",
            "loss: 0.416809  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 0.474855 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.324655  [    0/60000]\n",
            "loss: 0.484674  [ 6400/60000]\n",
            "loss: 0.288728  [12800/60000]\n",
            "loss: 0.511366  [19200/60000]\n",
            "loss: 0.437258  [25600/60000]\n",
            "loss: 0.451487  [32000/60000]\n",
            "loss: 0.455505  [38400/60000]\n",
            "loss: 0.640647  [44800/60000]\n",
            "loss: 0.583142  [51200/60000]\n",
            "loss: 0.415176  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 0.473552 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.321996  [    0/60000]\n",
            "loss: 0.483097  [ 6400/60000]\n",
            "loss: 0.287205  [12800/60000]\n",
            "loss: 0.509446  [19200/60000]\n",
            "loss: 0.434892  [25600/60000]\n",
            "loss: 0.449810  [32000/60000]\n",
            "loss: 0.453944  [38400/60000]\n",
            "loss: 0.639048  [44800/60000]\n",
            "loss: 0.581588  [51200/60000]\n",
            "loss: 0.413631  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 0.472286 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.319410  [    0/60000]\n",
            "loss: 0.481536  [ 6400/60000]\n",
            "loss: 0.285748  [12800/60000]\n",
            "loss: 0.507607  [19200/60000]\n",
            "loss: 0.432557  [25600/60000]\n",
            "loss: 0.448223  [32000/60000]\n",
            "loss: 0.452420  [38400/60000]\n",
            "loss: 0.637468  [44800/60000]\n",
            "loss: 0.580028  [51200/60000]\n",
            "loss: 0.412164  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 0.471050 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.316915  [    0/60000]\n",
            "loss: 0.480007  [ 6400/60000]\n",
            "loss: 0.284324  [12800/60000]\n",
            "loss: 0.505823  [19200/60000]\n",
            "loss: 0.430249  [25600/60000]\n",
            "loss: 0.446698  [32000/60000]\n",
            "loss: 0.450942  [38400/60000]\n",
            "loss: 0.635890  [44800/60000]\n",
            "loss: 0.578498  [51200/60000]\n",
            "loss: 0.410796  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 0.469843 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.314512  [    0/60000]\n",
            "loss: 0.478512  [ 6400/60000]\n",
            "loss: 0.282937  [12800/60000]\n",
            "loss: 0.504142  [19200/60000]\n",
            "loss: 0.427970  [25600/60000]\n",
            "loss: 0.445211  [32000/60000]\n",
            "loss: 0.449482  [38400/60000]\n",
            "loss: 0.634314  [44800/60000]\n",
            "loss: 0.576930  [51200/60000]\n",
            "loss: 0.409520  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 0.468668 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.312221  [    0/60000]\n",
            "loss: 0.477040  [ 6400/60000]\n",
            "loss: 0.281574  [12800/60000]\n",
            "loss: 0.502523  [19200/60000]\n",
            "loss: 0.425772  [25600/60000]\n",
            "loss: 0.443743  [32000/60000]\n",
            "loss: 0.448073  [38400/60000]\n",
            "loss: 0.632746  [44800/60000]\n",
            "loss: 0.575432  [51200/60000]\n",
            "loss: 0.408308  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.467517 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.309989  [    0/60000]\n",
            "loss: 0.475569  [ 6400/60000]\n",
            "loss: 0.280263  [12800/60000]\n",
            "loss: 0.500966  [19200/60000]\n",
            "loss: 0.423640  [25600/60000]\n",
            "loss: 0.442307  [32000/60000]\n",
            "loss: 0.446697  [38400/60000]\n",
            "loss: 0.631205  [44800/60000]\n",
            "loss: 0.573903  [51200/60000]\n",
            "loss: 0.407154  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.466395 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.307843  [    0/60000]\n",
            "loss: 0.474103  [ 6400/60000]\n",
            "loss: 0.279001  [12800/60000]\n",
            "loss: 0.499449  [19200/60000]\n",
            "loss: 0.421526  [25600/60000]\n",
            "loss: 0.440972  [32000/60000]\n",
            "loss: 0.445335  [38400/60000]\n",
            "loss: 0.629686  [44800/60000]\n",
            "loss: 0.572430  [51200/60000]\n",
            "loss: 0.406011  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.465299 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.305773  [    0/60000]\n",
            "loss: 0.472661  [ 6400/60000]\n",
            "loss: 0.277757  [12800/60000]\n",
            "loss: 0.497935  [19200/60000]\n",
            "loss: 0.419457  [25600/60000]\n",
            "loss: 0.439701  [32000/60000]\n",
            "loss: 0.444016  [38400/60000]\n",
            "loss: 0.628185  [44800/60000]\n",
            "loss: 0.570982  [51200/60000]\n",
            "loss: 0.404912  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.464226 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.303737  [    0/60000]\n",
            "loss: 0.471246  [ 6400/60000]\n",
            "loss: 0.276580  [12800/60000]\n",
            "loss: 0.496469  [19200/60000]\n",
            "loss: 0.417387  [25600/60000]\n",
            "loss: 0.438441  [32000/60000]\n",
            "loss: 0.442688  [38400/60000]\n",
            "loss: 0.626730  [44800/60000]\n",
            "loss: 0.569567  [51200/60000]\n",
            "loss: 0.403872  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.6%, Avg loss: 0.463177 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.301771  [    0/60000]\n",
            "loss: 0.469831  [ 6400/60000]\n",
            "loss: 0.275428  [12800/60000]\n",
            "loss: 0.495023  [19200/60000]\n",
            "loss: 0.415345  [25600/60000]\n",
            "loss: 0.437200  [32000/60000]\n",
            "loss: 0.441383  [38400/60000]\n",
            "loss: 0.625248  [44800/60000]\n",
            "loss: 0.568179  [51200/60000]\n",
            "loss: 0.402838  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 0.462149 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.299867  [    0/60000]\n",
            "loss: 0.468422  [ 6400/60000]\n",
            "loss: 0.274312  [12800/60000]\n",
            "loss: 0.493632  [19200/60000]\n",
            "loss: 0.413332  [25600/60000]\n",
            "loss: 0.435944  [32000/60000]\n",
            "loss: 0.440143  [38400/60000]\n",
            "loss: 0.623728  [44800/60000]\n",
            "loss: 0.566774  [51200/60000]\n",
            "loss: 0.401878  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 0.461140 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.298011  [    0/60000]\n",
            "loss: 0.467033  [ 6400/60000]\n",
            "loss: 0.273232  [12800/60000]\n",
            "loss: 0.492301  [19200/60000]\n",
            "loss: 0.411370  [25600/60000]\n",
            "loss: 0.434708  [32000/60000]\n",
            "loss: 0.438877  [38400/60000]\n",
            "loss: 0.622274  [44800/60000]\n",
            "loss: 0.565372  [51200/60000]\n",
            "loss: 0.400970  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 0.460152 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.296255  [    0/60000]\n",
            "loss: 0.465642  [ 6400/60000]\n",
            "loss: 0.272178  [12800/60000]\n",
            "loss: 0.490977  [19200/60000]\n",
            "loss: 0.409452  [25600/60000]\n",
            "loss: 0.433495  [32000/60000]\n",
            "loss: 0.437627  [38400/60000]\n",
            "loss: 0.620863  [44800/60000]\n",
            "loss: 0.564033  [51200/60000]\n",
            "loss: 0.400086  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.8%, Avg loss: 0.459181 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.294548  [    0/60000]\n",
            "loss: 0.464259  [ 6400/60000]\n",
            "loss: 0.271160  [12800/60000]\n",
            "loss: 0.489681  [19200/60000]\n",
            "loss: 0.407520  [25600/60000]\n",
            "loss: 0.432331  [32000/60000]\n",
            "loss: 0.436439  [38400/60000]\n",
            "loss: 0.619449  [44800/60000]\n",
            "loss: 0.562658  [51200/60000]\n",
            "loss: 0.399226  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.8%, Avg loss: 0.458228 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.292860  [    0/60000]\n",
            "loss: 0.462854  [ 6400/60000]\n",
            "loss: 0.270158  [12800/60000]\n",
            "loss: 0.488440  [19200/60000]\n",
            "loss: 0.405592  [25600/60000]\n",
            "loss: 0.431225  [32000/60000]\n",
            "loss: 0.435294  [38400/60000]\n",
            "loss: 0.618068  [44800/60000]\n",
            "loss: 0.561346  [51200/60000]\n",
            "loss: 0.398430  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.457289 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.291224  [    0/60000]\n",
            "loss: 0.461470  [ 6400/60000]\n",
            "loss: 0.269173  [12800/60000]\n",
            "loss: 0.487192  [19200/60000]\n",
            "loss: 0.403737  [25600/60000]\n",
            "loss: 0.430138  [32000/60000]\n",
            "loss: 0.434138  [38400/60000]\n",
            "loss: 0.616780  [44800/60000]\n",
            "loss: 0.560062  [51200/60000]\n",
            "loss: 0.397689  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.456371 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.289650  [    0/60000]\n",
            "loss: 0.460096  [ 6400/60000]\n",
            "loss: 0.268194  [12800/60000]\n",
            "loss: 0.485990  [19200/60000]\n",
            "loss: 0.401894  [25600/60000]\n",
            "loss: 0.428991  [32000/60000]\n",
            "loss: 0.433004  [38400/60000]\n",
            "loss: 0.615436  [44800/60000]\n",
            "loss: 0.558754  [51200/60000]\n",
            "loss: 0.396955  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.455462 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.288110  [    0/60000]\n",
            "loss: 0.458762  [ 6400/60000]\n",
            "loss: 0.267196  [12800/60000]\n",
            "loss: 0.484819  [19200/60000]\n",
            "loss: 0.400095  [25600/60000]\n",
            "loss: 0.427880  [32000/60000]\n",
            "loss: 0.431844  [38400/60000]\n",
            "loss: 0.614110  [44800/60000]\n",
            "loss: 0.557454  [51200/60000]\n",
            "loss: 0.396242  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.454568 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.286627  [    0/60000]\n",
            "loss: 0.457425  [ 6400/60000]\n",
            "loss: 0.266254  [12800/60000]\n",
            "loss: 0.483651  [19200/60000]\n",
            "loss: 0.398312  [25600/60000]\n",
            "loss: 0.426763  [32000/60000]\n",
            "loss: 0.430718  [38400/60000]\n",
            "loss: 0.612764  [44800/60000]\n",
            "loss: 0.556185  [51200/60000]\n",
            "loss: 0.395596  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.453686 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.285196  [    0/60000]\n",
            "loss: 0.456068  [ 6400/60000]\n",
            "loss: 0.265315  [12800/60000]\n",
            "loss: 0.482507  [19200/60000]\n",
            "loss: 0.396614  [25600/60000]\n",
            "loss: 0.425685  [32000/60000]\n",
            "loss: 0.429625  [38400/60000]\n",
            "loss: 0.611458  [44800/60000]\n",
            "loss: 0.554917  [51200/60000]\n",
            "loss: 0.394964  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.452812 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.283858  [    0/60000]\n",
            "loss: 0.454761  [ 6400/60000]\n",
            "loss: 0.264364  [12800/60000]\n",
            "loss: 0.481422  [19200/60000]\n",
            "loss: 0.394908  [25600/60000]\n",
            "loss: 0.424703  [32000/60000]\n",
            "loss: 0.428554  [38400/60000]\n",
            "loss: 0.610182  [44800/60000]\n",
            "loss: 0.553693  [51200/60000]\n",
            "loss: 0.394290  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.451929 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.282513  [    0/60000]\n",
            "loss: 0.453398  [ 6400/60000]\n",
            "loss: 0.263391  [12800/60000]\n",
            "loss: 0.480334  [19200/60000]\n",
            "loss: 0.393187  [25600/60000]\n",
            "loss: 0.423768  [32000/60000]\n",
            "loss: 0.427509  [38400/60000]\n",
            "loss: 0.608936  [44800/60000]\n",
            "loss: 0.552454  [51200/60000]\n",
            "loss: 0.393611  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.1%, Avg loss: 0.451068 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.281173  [    0/60000]\n",
            "loss: 0.452123  [ 6400/60000]\n",
            "loss: 0.262507  [12800/60000]\n",
            "loss: 0.479279  [19200/60000]\n",
            "loss: 0.391523  [25600/60000]\n",
            "loss: 0.422723  [32000/60000]\n",
            "loss: 0.426491  [38400/60000]\n",
            "loss: 0.607707  [44800/60000]\n",
            "loss: 0.551181  [51200/60000]\n",
            "loss: 0.392928  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.1%, Avg loss: 0.450232 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.279902  [    0/60000]\n",
            "loss: 0.450918  [ 6400/60000]\n",
            "loss: 0.261661  [12800/60000]\n",
            "loss: 0.478224  [19200/60000]\n",
            "loss: 0.389836  [25600/60000]\n",
            "loss: 0.421727  [32000/60000]\n",
            "loss: 0.425435  [38400/60000]\n",
            "loss: 0.606487  [44800/60000]\n",
            "loss: 0.549921  [51200/60000]\n",
            "loss: 0.392273  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.1%, Avg loss: 0.449408 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.278654  [    0/60000]\n",
            "loss: 0.449730  [ 6400/60000]\n",
            "loss: 0.260807  [12800/60000]\n",
            "loss: 0.477101  [19200/60000]\n",
            "loss: 0.388190  [25600/60000]\n",
            "loss: 0.420772  [32000/60000]\n",
            "loss: 0.424382  [38400/60000]\n",
            "loss: 0.605297  [44800/60000]\n",
            "loss: 0.548644  [51200/60000]\n",
            "loss: 0.391642  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.1%, Avg loss: 0.448598 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.277427  [    0/60000]\n",
            "loss: 0.448527  [ 6400/60000]\n",
            "loss: 0.259989  [12800/60000]\n",
            "loss: 0.475996  [19200/60000]\n",
            "loss: 0.386637  [25600/60000]\n",
            "loss: 0.419730  [32000/60000]\n",
            "loss: 0.423349  [38400/60000]\n",
            "loss: 0.604107  [44800/60000]\n",
            "loss: 0.547397  [51200/60000]\n",
            "loss: 0.391059  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 0.447800 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.276247  [    0/60000]\n",
            "loss: 0.447318  [ 6400/60000]\n",
            "loss: 0.259182  [12800/60000]\n",
            "loss: 0.474885  [19200/60000]\n",
            "loss: 0.385069  [25600/60000]\n",
            "loss: 0.418681  [32000/60000]\n",
            "loss: 0.422364  [38400/60000]\n",
            "loss: 0.602884  [44800/60000]\n",
            "loss: 0.546127  [51200/60000]\n",
            "loss: 0.390469  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 0.447010 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.275059  [    0/60000]\n",
            "loss: 0.446146  [ 6400/60000]\n",
            "loss: 0.258376  [12800/60000]\n",
            "loss: 0.473786  [19200/60000]\n",
            "loss: 0.383536  [25600/60000]\n",
            "loss: 0.417613  [32000/60000]\n",
            "loss: 0.421394  [38400/60000]\n",
            "loss: 0.601712  [44800/60000]\n",
            "loss: 0.544866  [51200/60000]\n",
            "loss: 0.389911  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 0.446230 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.273961  [    0/60000]\n",
            "loss: 0.444958  [ 6400/60000]\n",
            "loss: 0.257594  [12800/60000]\n",
            "loss: 0.472678  [19200/60000]\n",
            "loss: 0.382037  [25600/60000]\n",
            "loss: 0.416532  [32000/60000]\n",
            "loss: 0.420405  [38400/60000]\n",
            "loss: 0.600564  [44800/60000]\n",
            "loss: 0.543672  [51200/60000]\n",
            "loss: 0.389364  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 0.445457 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.272943  [    0/60000]\n",
            "loss: 0.443835  [ 6400/60000]\n",
            "loss: 0.256857  [12800/60000]\n",
            "loss: 0.471594  [19200/60000]\n",
            "loss: 0.380530  [25600/60000]\n",
            "loss: 0.415560  [32000/60000]\n",
            "loss: 0.419401  [38400/60000]\n",
            "loss: 0.599471  [44800/60000]\n",
            "loss: 0.542454  [51200/60000]\n",
            "loss: 0.388862  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.444695 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.271940  [    0/60000]\n",
            "loss: 0.442681  [ 6400/60000]\n",
            "loss: 0.256113  [12800/60000]\n",
            "loss: 0.470518  [19200/60000]\n",
            "loss: 0.379047  [25600/60000]\n",
            "loss: 0.414561  [32000/60000]\n",
            "loss: 0.418376  [38400/60000]\n",
            "loss: 0.598401  [44800/60000]\n",
            "loss: 0.541203  [51200/60000]\n",
            "loss: 0.388339  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.443944 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.270950  [    0/60000]\n",
            "loss: 0.441523  [ 6400/60000]\n",
            "loss: 0.255398  [12800/60000]\n",
            "loss: 0.469426  [19200/60000]\n",
            "loss: 0.377575  [25600/60000]\n",
            "loss: 0.413548  [32000/60000]\n",
            "loss: 0.417357  [38400/60000]\n",
            "loss: 0.597343  [44800/60000]\n",
            "loss: 0.540014  [51200/60000]\n",
            "loss: 0.387788  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.443196 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.269976  [    0/60000]\n",
            "loss: 0.440411  [ 6400/60000]\n",
            "loss: 0.254656  [12800/60000]\n",
            "loss: 0.468342  [19200/60000]\n",
            "loss: 0.376079  [25600/60000]\n",
            "loss: 0.412571  [32000/60000]\n",
            "loss: 0.416357  [38400/60000]\n",
            "loss: 0.596282  [44800/60000]\n",
            "loss: 0.538845  [51200/60000]\n",
            "loss: 0.387312  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.442463 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.269027  [    0/60000]\n",
            "loss: 0.439301  [ 6400/60000]\n",
            "loss: 0.253946  [12800/60000]\n",
            "loss: 0.467295  [19200/60000]\n",
            "loss: 0.374630  [25600/60000]\n",
            "loss: 0.411616  [32000/60000]\n",
            "loss: 0.415337  [38400/60000]\n",
            "loss: 0.595191  [44800/60000]\n",
            "loss: 0.537692  [51200/60000]\n",
            "loss: 0.386761  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.441730 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.268091  [    0/60000]\n",
            "loss: 0.438205  [ 6400/60000]\n",
            "loss: 0.253254  [12800/60000]\n",
            "loss: 0.466264  [19200/60000]\n",
            "loss: 0.373169  [25600/60000]\n",
            "loss: 0.410623  [32000/60000]\n",
            "loss: 0.414367  [38400/60000]\n",
            "loss: 0.594139  [44800/60000]\n",
            "loss: 0.536591  [51200/60000]\n",
            "loss: 0.386299  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.441003 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.267181  [    0/60000]\n",
            "loss: 0.437151  [ 6400/60000]\n",
            "loss: 0.252569  [12800/60000]\n",
            "loss: 0.465243  [19200/60000]\n",
            "loss: 0.371706  [25600/60000]\n",
            "loss: 0.409682  [32000/60000]\n",
            "loss: 0.413382  [38400/60000]\n",
            "loss: 0.593133  [44800/60000]\n",
            "loss: 0.535491  [51200/60000]\n",
            "loss: 0.385817  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.440281 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.266305  [    0/60000]\n",
            "loss: 0.436096  [ 6400/60000]\n",
            "loss: 0.251915  [12800/60000]\n",
            "loss: 0.464207  [19200/60000]\n",
            "loss: 0.370294  [25600/60000]\n",
            "loss: 0.408732  [32000/60000]\n",
            "loss: 0.412445  [38400/60000]\n",
            "loss: 0.592126  [44800/60000]\n",
            "loss: 0.534266  [51200/60000]\n",
            "loss: 0.385349  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.439563 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.265446  [    0/60000]\n",
            "loss: 0.435045  [ 6400/60000]\n",
            "loss: 0.251267  [12800/60000]\n",
            "loss: 0.463202  [19200/60000]\n",
            "loss: 0.368907  [25600/60000]\n",
            "loss: 0.407787  [32000/60000]\n",
            "loss: 0.411561  [38400/60000]\n",
            "loss: 0.591092  [44800/60000]\n",
            "loss: 0.533052  [51200/60000]\n",
            "loss: 0.384861  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.438848 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.264631  [    0/60000]\n",
            "loss: 0.433963  [ 6400/60000]\n",
            "loss: 0.250608  [12800/60000]\n",
            "loss: 0.462170  [19200/60000]\n",
            "loss: 0.367507  [25600/60000]\n",
            "loss: 0.406844  [32000/60000]\n",
            "loss: 0.410625  [38400/60000]\n",
            "loss: 0.590154  [44800/60000]\n",
            "loss: 0.531852  [51200/60000]\n",
            "loss: 0.384339  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.438142 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.263786  [    0/60000]\n",
            "loss: 0.432870  [ 6400/60000]\n",
            "loss: 0.249935  [12800/60000]\n",
            "loss: 0.461153  [19200/60000]\n",
            "loss: 0.366130  [25600/60000]\n",
            "loss: 0.405874  [32000/60000]\n",
            "loss: 0.409717  [38400/60000]\n",
            "loss: 0.589200  [44800/60000]\n",
            "loss: 0.530701  [51200/60000]\n",
            "loss: 0.383877  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.437449 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.262959  [    0/60000]\n",
            "loss: 0.431753  [ 6400/60000]\n",
            "loss: 0.249267  [12800/60000]\n",
            "loss: 0.460081  [19200/60000]\n",
            "loss: 0.364777  [25600/60000]\n",
            "loss: 0.404927  [32000/60000]\n",
            "loss: 0.408808  [38400/60000]\n",
            "loss: 0.588218  [44800/60000]\n",
            "loss: 0.529527  [51200/60000]\n",
            "loss: 0.383455  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.436758 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.262135  [    0/60000]\n",
            "loss: 0.430636  [ 6400/60000]\n",
            "loss: 0.248603  [12800/60000]\n",
            "loss: 0.459039  [19200/60000]\n",
            "loss: 0.363463  [25600/60000]\n",
            "loss: 0.404041  [32000/60000]\n",
            "loss: 0.407884  [38400/60000]\n",
            "loss: 0.587221  [44800/60000]\n",
            "loss: 0.528335  [51200/60000]\n",
            "loss: 0.383015  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.436074 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.261309  [    0/60000]\n",
            "loss: 0.429545  [ 6400/60000]\n",
            "loss: 0.247939  [12800/60000]\n",
            "loss: 0.457993  [19200/60000]\n",
            "loss: 0.362148  [25600/60000]\n",
            "loss: 0.403164  [32000/60000]\n",
            "loss: 0.406961  [38400/60000]\n",
            "loss: 0.586205  [44800/60000]\n",
            "loss: 0.527175  [51200/60000]\n",
            "loss: 0.382560  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.435396 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.260541  [    0/60000]\n",
            "loss: 0.428456  [ 6400/60000]\n",
            "loss: 0.247288  [12800/60000]\n",
            "loss: 0.456970  [19200/60000]\n",
            "loss: 0.360890  [25600/60000]\n",
            "loss: 0.402303  [32000/60000]\n",
            "loss: 0.405995  [38400/60000]\n",
            "loss: 0.585230  [44800/60000]\n",
            "loss: 0.526058  [51200/60000]\n",
            "loss: 0.382099  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.434715 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.259773  [    0/60000]\n",
            "loss: 0.427437  [ 6400/60000]\n",
            "loss: 0.246633  [12800/60000]\n",
            "loss: 0.455917  [19200/60000]\n",
            "loss: 0.359610  [25600/60000]\n",
            "loss: 0.401425  [32000/60000]\n",
            "loss: 0.405006  [38400/60000]\n",
            "loss: 0.584298  [44800/60000]\n",
            "loss: 0.524862  [51200/60000]\n",
            "loss: 0.381623  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.434039 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.259028  [    0/60000]\n",
            "loss: 0.426449  [ 6400/60000]\n",
            "loss: 0.246025  [12800/60000]\n",
            "loss: 0.454907  [19200/60000]\n",
            "loss: 0.358315  [25600/60000]\n",
            "loss: 0.400516  [32000/60000]\n",
            "loss: 0.404005  [38400/60000]\n",
            "loss: 0.583376  [44800/60000]\n",
            "loss: 0.523698  [51200/60000]\n",
            "loss: 0.381171  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.433372 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.258270  [    0/60000]\n",
            "loss: 0.425441  [ 6400/60000]\n",
            "loss: 0.245415  [12800/60000]\n",
            "loss: 0.453918  [19200/60000]\n",
            "loss: 0.357016  [25600/60000]\n",
            "loss: 0.399626  [32000/60000]\n",
            "loss: 0.402994  [38400/60000]\n",
            "loss: 0.582394  [44800/60000]\n",
            "loss: 0.522518  [51200/60000]\n",
            "loss: 0.380734  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.432707 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.257490  [    0/60000]\n",
            "loss: 0.424423  [ 6400/60000]\n",
            "loss: 0.244840  [12800/60000]\n",
            "loss: 0.452959  [19200/60000]\n",
            "loss: 0.355708  [25600/60000]\n",
            "loss: 0.398772  [32000/60000]\n",
            "loss: 0.401953  [38400/60000]\n",
            "loss: 0.581396  [44800/60000]\n",
            "loss: 0.521356  [51200/60000]\n",
            "loss: 0.380318  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.432050 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.256748  [    0/60000]\n",
            "loss: 0.423417  [ 6400/60000]\n",
            "loss: 0.244291  [12800/60000]\n",
            "loss: 0.451994  [19200/60000]\n",
            "loss: 0.354420  [25600/60000]\n",
            "loss: 0.397970  [32000/60000]\n",
            "loss: 0.400905  [38400/60000]\n",
            "loss: 0.580423  [44800/60000]\n",
            "loss: 0.520189  [51200/60000]\n",
            "loss: 0.379927  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.431395 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.256064  [    0/60000]\n",
            "loss: 0.422416  [ 6400/60000]\n",
            "loss: 0.243721  [12800/60000]\n",
            "loss: 0.451040  [19200/60000]\n",
            "loss: 0.353182  [25600/60000]\n",
            "loss: 0.397123  [32000/60000]\n",
            "loss: 0.399749  [38400/60000]\n",
            "loss: 0.579531  [44800/60000]\n",
            "loss: 0.519044  [51200/60000]\n",
            "loss: 0.379494  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.430745 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.255346  [    0/60000]\n",
            "loss: 0.421447  [ 6400/60000]\n",
            "loss: 0.243182  [12800/60000]\n",
            "loss: 0.450068  [19200/60000]\n",
            "loss: 0.352016  [25600/60000]\n",
            "loss: 0.396315  [32000/60000]\n",
            "loss: 0.398601  [38400/60000]\n",
            "loss: 0.578647  [44800/60000]\n",
            "loss: 0.517816  [51200/60000]\n",
            "loss: 0.379072  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.430096 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.254691  [    0/60000]\n",
            "loss: 0.420460  [ 6400/60000]\n",
            "loss: 0.242639  [12800/60000]\n",
            "loss: 0.449090  [19200/60000]\n",
            "loss: 0.350830  [25600/60000]\n",
            "loss: 0.395548  [32000/60000]\n",
            "loss: 0.397505  [38400/60000]\n",
            "loss: 0.577773  [44800/60000]\n",
            "loss: 0.516697  [51200/60000]\n",
            "loss: 0.378639  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.429455 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.254050  [    0/60000]\n",
            "loss: 0.419531  [ 6400/60000]\n",
            "loss: 0.242081  [12800/60000]\n",
            "loss: 0.448064  [19200/60000]\n",
            "loss: 0.349756  [25600/60000]\n",
            "loss: 0.394708  [32000/60000]\n",
            "loss: 0.396374  [38400/60000]\n",
            "loss: 0.576818  [44800/60000]\n",
            "loss: 0.515642  [51200/60000]\n",
            "loss: 0.378234  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.428818 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.253382  [    0/60000]\n",
            "loss: 0.418633  [ 6400/60000]\n",
            "loss: 0.241572  [12800/60000]\n",
            "loss: 0.447032  [19200/60000]\n",
            "loss: 0.348692  [25600/60000]\n",
            "loss: 0.393956  [32000/60000]\n",
            "loss: 0.395250  [38400/60000]\n",
            "loss: 0.575880  [44800/60000]\n",
            "loss: 0.514591  [51200/60000]\n",
            "loss: 0.377726  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.428180 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.252698  [    0/60000]\n",
            "loss: 0.417681  [ 6400/60000]\n",
            "loss: 0.241082  [12800/60000]\n",
            "loss: 0.446081  [19200/60000]\n",
            "loss: 0.347675  [25600/60000]\n",
            "loss: 0.393135  [32000/60000]\n",
            "loss: 0.394172  [38400/60000]\n",
            "loss: 0.574956  [44800/60000]\n",
            "loss: 0.513569  [51200/60000]\n",
            "loss: 0.377193  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.427545 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.252057  [    0/60000]\n",
            "loss: 0.416735  [ 6400/60000]\n",
            "loss: 0.240634  [12800/60000]\n",
            "loss: 0.445141  [19200/60000]\n",
            "loss: 0.346683  [25600/60000]\n",
            "loss: 0.392325  [32000/60000]\n",
            "loss: 0.393083  [38400/60000]\n",
            "loss: 0.574070  [44800/60000]\n",
            "loss: 0.512605  [51200/60000]\n",
            "loss: 0.376614  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.426918 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.251391  [    0/60000]\n",
            "loss: 0.415790  [ 6400/60000]\n",
            "loss: 0.240232  [12800/60000]\n",
            "loss: 0.444274  [19200/60000]\n",
            "loss: 0.345673  [25600/60000]\n",
            "loss: 0.391493  [32000/60000]\n",
            "loss: 0.392101  [38400/60000]\n",
            "loss: 0.573097  [44800/60000]\n",
            "loss: 0.511581  [51200/60000]\n",
            "loss: 0.375938  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.426293 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.250723  [    0/60000]\n",
            "loss: 0.414884  [ 6400/60000]\n",
            "loss: 0.239809  [12800/60000]\n",
            "loss: 0.443382  [19200/60000]\n",
            "loss: 0.344597  [25600/60000]\n",
            "loss: 0.390674  [32000/60000]\n",
            "loss: 0.391086  [38400/60000]\n",
            "loss: 0.572080  [44800/60000]\n",
            "loss: 0.510662  [51200/60000]\n",
            "loss: 0.375330  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.425667 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.250106  [    0/60000]\n",
            "loss: 0.413956  [ 6400/60000]\n",
            "loss: 0.239388  [12800/60000]\n",
            "loss: 0.442513  [19200/60000]\n",
            "loss: 0.343534  [25600/60000]\n",
            "loss: 0.389944  [32000/60000]\n",
            "loss: 0.390041  [38400/60000]\n",
            "loss: 0.571088  [44800/60000]\n",
            "loss: 0.509672  [51200/60000]\n",
            "loss: 0.374809  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.425050 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.249519  [    0/60000]\n",
            "loss: 0.412986  [ 6400/60000]\n",
            "loss: 0.238892  [12800/60000]\n",
            "loss: 0.441567  [19200/60000]\n",
            "loss: 0.342503  [25600/60000]\n",
            "loss: 0.389192  [32000/60000]\n",
            "loss: 0.389026  [38400/60000]\n",
            "loss: 0.570060  [44800/60000]\n",
            "loss: 0.508702  [51200/60000]\n",
            "loss: 0.374314  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.0%, Avg loss: 0.424437 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZajJADtqp8LA",
        "outputId": "251610a1-1aa7-4e03-b00a-4805240f6135"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F2XPUEWqA4X",
        "outputId": "c227edb0-fbf0-424f-8f4c-5d9854f73df8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iBUrToWqC43",
        "outputId": "0e5d3f88-f99d-488e-8c8b-59bb05fb7125"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    }
  ]
}